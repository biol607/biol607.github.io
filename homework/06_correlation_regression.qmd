---
title: "Correlation And Regression Homework"
author: "Biol 607"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE, message=FALSE)
library(tidyverse)
```

Note: Datasets are available at http://whitlockschluter.zoology.ubc.ca/data so you don't have to type anything in (and have to load it!)  


## 1. Correlation - W&S Chapter 16
Data at https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter16/chap16q15LanguageGreyMatter.csv
![](images/16_15.png)
Remember, a correlation is just a regression on z-transformed variables. Also, note - *skip part c for now*. But the assumptions are still the assumptions of doing a correlation!


## 2. W&S Chapter 17
Data at https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q19GrasslandNutrientsPlantSpecies.csv

![](./images/17_19.png)
Ignore part d.

## 3. W&S Chapter 17-25
https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q25BeetleWingsAndHorns.csv
![](images/17-25a.png)

![](images/17-25b.png)

e. Do any other diagnostics misbehave?



## 4. W&S Chapter 17-30
https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q30NuclearTeeth.csv
![](images/17-30.png)

d. Using `broom::augment()` and `geom_ribbon()` in ggplot2, reproduce the above plot showing data, fit, fit interval, and prediction interval.


## Impress Yourself! Intervals and simulation

Fit the deet and bites model from lab.

```{r}
deet <- read.csv("./data/17q24DEETMosquiteBites.csv")

ggplot(deet, aes(dose, bites)) +
  geom_point() +
  stat_smooth(method=lm)


```

Now, look at `vcov()` applied to your fit. For example:

```{r, echo = TRUE}
deet_mod <- lm(bites ~ dose, data = deet)

vcov(deet_mod)
```

What you have here is the variance-covariance matrix of the parameters of the model. In essence, every time you larger slopes in this case will have smaller intercepts, and vice-verse. This maintains the best fit possible, despite deviations in the slope and intercept.  BUT - what's cool about this is that it also allows us to produce simulations (posterior simulations for anyone interested) of the fit. We can use a package like `mnormt` that let's us draw from a multivariate normal distribution when provided with a vcov matrix.  For example...


```{r mnorm, echo=TRUE}
library(mnormt)

rmnorm(4, mean = coef(deet_mod), varcov = vcov(deet_mod))
```

produces a number of draws of the variance and the covariance!

### IYa. Fit simulations!
Using `geom_abline()` (look at the helpfile - you'll see instantly why it's good here!) make a plot that has the following layers and shows that these simulated lines match up well with the fit CI. 1) the data, 2) the lm fit with a CI, and 3) simulated lines. You might have to much around to make it look as good as possible.


```{r, eval=FALSE}
coef_sims <- rmnorm(500, mean = coef(deet_mod), varcov = vcov(deet_mod)) %>%
  as.data.frame

ggplot(deet, aes(dose, bites)) +
  geom_point() +
  geom_abline(data = coef_sims, aes(slope = dose, intercept = `(Intercept)`), alpha = 0.5) +
  stat_smooth(data = deet, method=lm, fill = "red")
```

### IYb. Prediction simulations!

That's all well and good, but what about the prediction intervals? To each line, we can add some error drawn from the residual standard deviation. That residual can either be extracted from `summary()` or you can get the `sd` of `residuals`.

Now, visualize the simulated prediction interval around the fit versus the calculated prediction interval around the fit via `predict`. **Go HAM with a clever visualization of all elements on one figure - however you would like**

```{r, warning = FALSE, eval=FALSE}
coef_sims <- coef_sims %>%
  mutate(error = rnorm(n(), 0, sd(deet_mod$residuals)))

pred_frame <- predict(deet_mod, interval="prediction") %>% cbind(deet)

ggplot(deet, aes(dose, bites)) +
  geom_point() +
  geom_abline(data = coef_sims, aes(slope = dose, intercept = error+`(Intercept)`), alpha = 0.5, color = "orange") +
  geom_ribbon(data = pred_frame, aes(ymin = lwr, ymax = upr), fill = "purple", alpha = 0.5) +
  geom_abline(data = coef_sims, aes(slope = dose, intercept = `(Intercept)`), alpha = 0.5) +
  stat_smooth(data = deet, method=lm, fill = "red")

```



----


## Meta 1. 
How well do you feel you understand the assumption testing behind a linear model? If there are elements that confuse you, what are they? Why?

## Meta 2. 
What concepts of linear regression are the clearest for you? Which are the most opaque?

## Meta 3.
Even if you did not do the IYKYK part of this assignment, do you see how simulation can be used with a fit model? Do you feel it would be useful? Do you have gaps in your understanding about why simulation could work here?

## Meta 3. 
How much time did this take you, roughly? Again, I'm trying to keep track that these assignments aren't killer, more than anything.  

## Meta 4. 
Please give yourself a weak/sufficient/strong assessment on this assigment. Feel free to comment on why.

