---
title: "ANOVA"
author: "Biol 607"
output:
  html_document:
    toc: true
    toc_depth: 5
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
```

For this lab, see the etherpad at  https://etherpad.wikimedia.org/p/607-anova-2018

## 1.One-Way ANOVA Model
We'll start today with the dataset `15e1KneesWhoSayNight.csv` about an experiment to help resolve jetlag by having people shine lights at different parts of themselves to try and shift their internal clocks.

```{r knees}
library(tidyverse)

knees <- read_csv("./data/10/15e1KneesWhoSayNight.csv")
```

We can see the outcomes with `ggplot2`

```{r knees_plot}
library(ggplot2)
ggplot(knees, mapping=aes(x=treatment, y=shift)) +
  stat_summary(color="red", size=1.3) +
    geom_point(alpha=0.7) +
  theme_bw(base_size=17)
```

### 1.1 LM, AOV, and Factors
As the underlying model of ANOVA is a linear one, we fit ANOVAs using `lm()` just as with linear regression.

```{r intro_knees}
knees <- read.csv("./data/10/15e1KneesWhoSayNight.csv")

knees_lm <- lm(shift ~ treatment, data=knees)
```

Now, there are two things to notice here. One, note that treatment is a either a character or factor. If it is not, because we are using `lm()`, it will be fit like a linear regression. So, beware!

There **is** an ANOVA-specific model fitting function - `aov`.

```{r aov}
knees_aov <- aov(shift ~ treatment, data=knees)
```

It's ok, I guess, and works with a few functions that `lm()` objects do not. But, in general, I find it too limiting. You can't see coefficients, etc. Boooooring.

### 1.2 Assumption Evaluation

Because this is an lm, we can check our assumptions as before - with one new one.  First, some oldies but goodies.

```{r assumptions}
#The whole par thing lets me make a multi-panel plot
par(mfrow=c(2,2))
plot(knees_lm, which=c(1,2,5))
par(mfrow=c(1,1))
```

Now, the residuals v. fitted lets us see how the residuals are distributed by treatment, but I often find it insufficient, as spacing on the x-axis can get odd. I could roll my own plot of resudials versus treatment, but, there's a **wonderful** package called `car` - which is from the book *Companion to Applied Regression* by John Fox. I recommend it highly! It has a function in it called `residualPlots()` which is useful here.

```{r residualPlots, warning=FALSE}
library(car)
residualPlots(knees_lm)
```

Note how it both does fitted v. residuals but also a boxplot by treatment. Handy, no?

### 1.3 F-Tests

OK, so, let's see the ANOVA table! With the function....`anova()`!

```{r anova}
anova(knees_lm)
```

Now....this is a type I sums of squares test. Which is fine for a 1-way ANOVA. If you want to start getting into the practice of using type II, `car` provides a function `Anova()` - note the capital A - which defaults to type II and I use instead. In fact, I use it all the time, as it handles a wide set of different models.

```{r Anova}
Anova(knees_lm)
```

Here it matters not a whit as you get the same table.


### 1.4 Post-hoc Tests

So, there are a lot of things we can do with a fit model

#### 1.4.0 Summary Output

```{r anova_summar}
summary(knees_lm)
```

First, notice that we get the same information as a linear regression - including $R^2$ and overall model F-test. THis is great. We also get coefficients, but, what do they mean?

Well, they are the treatment contrasts. Not super useful. R fits a model where treatment 1 is the intercept, and then we look at deviations from that initial treatment as your other coefficients. It's efficient, but, hard to make sense of. To not get an intercept term, you need to refit the model without the intercept. You can fit a whole new model with `-1` in the model formulation. Or, as I like to do to ensure I don't frak anything up, you can `update()` your model. Just use `.` to signify *what was there before*.

```{r update_summary}
knees_lm_no_int <- update(knees_lm, formula = . ~ . -1)

summary(knees_lm_no_int)
```

OK - that makes more sense. For a 1-way ANOVA, we can also see treatment means using the `emmeans` package - much more on that next week (and later below for contrasts).

```{r emmeans, message=FALSE}
library(emmeans)
library(multcompView)

emmeans(knees_lm, ~treatment)
```

I also like this because it outputs CIs.

We see means and if they are different from 0. But....what about post-hoc tests

#### 1.4.1 A Priori Contrasts

If you have a priori contrasts, you can use the `constrat` library to test them. You give contrast an a list and a b list. Then we get all comparisons of a v. b, in order. It's not great syntactically, but, it lets you do some pretty creative things.

```{r contrasts, message=FALSE}
contrast::contrast(knees_lm, 
         a = list(treatment = "control"), 
         b = list(treatment = "eyes"))
```

#### 1.4.2 Tukey's HSD
Meh. 9 times out of 10 we want to do something more like a Tukey Test. There is a `TukeyHSD` function that works on `aov` objects, but, if you're doing anything with an `lm`, it borks on you. Instead, let's use `emmeans`. It is wonderful as it's designed to work with ANOVA and ANCOVA models with complicated structures such that, for post-hocs, it adjusts to the mean or median level of all other factors. Very handy. 

```{r tukey_emmeans}
knees_em <- emmeans(knees_lm, ~treatment)

contrast(knees_em,
        method = "tukey")
```

We don't need to worry about many of the fancier things that emmeans does for the moment - those will become more useful with other models. But, we can look at this test a few different ways. First, we can visualize it

```{r plot_tukey}
plot(contrast(knees_em,
        method = "tukey")) +
  geom_vline(xintercept = 0, color = "red", lty=2)
```

We can also, using our tukey method of adjustment, get "groups" - i.e., see which groups are statistically the same versus different.

```{r groups}
library(multcompView)
cld(knees_em, adjust="tukey")
```

This can be very useful in plotting. For example, we can use that output as a data frame for a `ggplot` in a few different ways.

```{r plot_groups}
cld(knees_em, adjust="tukey") %>%
  ggplot(aes(x = treatment, y = emmean, 
             ymin = lower.CL, ymax = upper.CL,
             color = factor(.group))) +
  geom_pointrange() 


cld(knees_em, adjust="tukey") %>%
  mutate(.group = letters[as.numeric(.group)]) %>%
  ggplot(aes(x = treatment, y = emmean, 
             ymin = lower.CL, ymax = upper.CL)) +
  geom_pointrange() +
  geom_text(mapping = aes(label = .group), y = rep(1, 3)) +
  ylim(c(-2.5, 2))


knees_expanded <- left_join(knees, cld(knees_em, adjust="tukey"))
ggplot(knees_expanded,
       aes(x = treatment, y = shift, color = .group)) + 
  geom_point()
```

#### 1.4.2 Dunnet's Test

We can similarly use this to look at a Dunnett's test, which compares against the control
```{r bunnett_emmeans}
contrast(knees_em,
        method = "dunnett")
```

Note, if the "control" had not been the first treatment, you can either re-order the factor using `forcats` or just specify which of the levels is the control. For example, eyes is the second treatment. Let's make it our new reference.

```{r bunnett_emmeans_2}
contrast(knees_em,
        method = "dunnett", ref=2)
```

You can even plot these results
```{r plot_contrast}
plot(contrast(knees_em,
        method = "dunnett", ref=2)) +
  geom_vline(xintercept = 0, color = "red", lty=2)
```



#### 1.4.2 Bonferroni Correction and FDR

Let's say you wanted to do all pairwise tests, but, compare using a Bonferroni correction or FDR. Or none! No problem! There's an `adjust` argument

```{r tukey_emmeans_other_adjust}
contrast(knees_em,
        method = "tukey", adjust="bonferroni")


contrast(knees_em,
        method = "tukey", adjust="fdr")

contrast(knees_em,
        method = "tukey", adjust="none")
```



### 1.5 Faded Examples
Let's try three ANOVAs!
First - do landscape characteristics affect the number of generations plant species can exist before local extinction?

```{r plants, eval=FALSE}
plants <- read.csv("./data/10/15q01PlantPopulationPersistence.csv")

#Visualize
qplot(treatment, generations, data=plants, geom="boxplot")

#fit
plant_lm <- lm(generations ~ treatment, data=plants)

#assumptions
plot(plant_lm, which=c(1,2,4,5))

#ANOVA
anova(plant_lm)

#Tukey's HSD
contrast(emmeans(plant_lm, ~treatment), method = "tukey")
```

Second, how do different host types affect nematode longevity?


```{r nemetods, eval=FALSE}
worms <- read.csv("./data/10/15q19NematodeLifespan.csv")

#Visualize
qplot(treatment, lifespan, data=____, geom="____")

#fit
worm_lm <- lm(______ ~ ______, data=worms)

#assumptions
plot(______, which=c(1,2,4,5))

#ANOVA
anova(______)

#Tukey's HSD
contrast(emmeans(______, ~________), method = "tukey")
```

And last, how about how number of genotypes affect eelgrass productivity. Note, THERE IS A TRAP HERE. Look at your dataset before you do ANYTHING.

```{r eelgrass, eval=FALSE}
eelgrass <- read.csv("./data/10/15q05EelgrassGenotypes.csv")

#Visualize
________(treatment.genotypes, shoots, data=____, geom="____")

#fit
eelgrass_lm <- __(______ ~ ______, data=________)

#assumptions
________(______, which=c(1,2,4,5))

#ANOVA
________(______)

#Tukey's HSD
contrast(________(______, ~________), method = "________")
```

## 2. ANODEV (ANOVA + Likelihood)
If you had done this using likelihood, you could have done all of this with a LR Chisq also using `Anova()` from the `car` package.

```{r glm_anova}
knees_glm <- glm(shift ~ treatment, data=knees,
                 family=gaussian())

Anova(knees_glm)
```

Further, `emmeans` works here as well.

```{r glm_emmeans}
knees_glm_em <- emmeans(knees_glm, ~treatment)

cld(knees_glm_em)
```

And we can look at posthocs as usual

```{r glm_contrast}
contrast(knees_glm_em, method = "dunnett")
```

## 3. BANOVA

### 3.1 Fit and Summary
Yes, we can fit this using Bayesian methods as well. Here I'll use default priors (flat on the means).

```{r banova, message=FALSE, results = "hide"}
library(brms)
library(tidybayes)

knees_banova <- brm(shift ~ treatment,
                         data = knees,
                         family=gaussian(),
                     file = "knees_banova.rds")
```

We can actually examine this in a few different ways. First, there's a default method for looking at ANOVA-like models in `brms` using `margina_effects`

```{r marginal}
marginal_effects(knees_banova)
```

Neat, right?  We can also use `emmeans` as before.

```{r banova_emmeans}
knees_b_em <- emmeans(knees_banova, ~treatment)
knees_b_em
```

Note, now we're lookign at posteriod intervals (and you define that interval!)


### 3.2 BANOVA and Variance Partioning

An analogue to F-tests, although philosophically different, is to look at how the finite population variance - i.e. the variation of just your dataset rather than the entire super-population - is explained by different elements of the model. We'll explore this more next week, but, for now, let's get a feel for it. We want to visualize the variability in the model due to each source - i.e. treatment and residual in this case. Then, let's look at the posterior of this variance component, both in terms of raw numbers, and percentages.  

`emmeans` helps us out here again as it provides ready access to the treatment levels.

```{r banova_var_trt}
sd_treatment <- gather_emmeans_draws(knees_b_em) %>%
  group_by(.draw) %>%
  summarize(sd_treatment = sd(.value))
```

Extracting residuals is a bit trickier, as `tidybayes` does not yet have a nice residual extractor. I wrote some code for that - https://gist.github.com/jebyrnes/c28d1f5523be392e4666da2f06110c10 - and submitted an issue, but it might be a while until they get it.  

For now, we can use the `residuals` function with `summary=FALSE` which returns a giant matrix. We can manipulate the matrix a bit and summarise it to get the sd of residuals for each draw of the coefficients. Then, we can make a nice big tibble for plotting. I admit, this is a bit of a PITA, but, it will also help you get into the guts of BANOVA.

```{r banova_var_resid}
sd_residuals <- residuals(knees_banova, summary=FALSE) %>%
  t() %>%
  as.data.frame() %>%
  summarise_all(sd) %>%
  as.numeric
  
sd_groups <- tibble(type = c(rep("treatment", 4000),
                             rep("residual", 4000)),
                    value = c(sd_treatment$sd_treatment, sd_residuals))
```

Now we can plot this and look at it in a variety of ways.

```{r banova_view}
ggplot(sd_groups, 
       aes(x = value, y = type)) +
  geom_halfeyeh()
```

We can also make a table using a tidier from broom. `broom` has a wonderful function for summarizing MCMC results called `tidyMCMC` - but we need each posterior to have it's own column, so, we can make a new tibble.

```{r tab_bayes}
sd_bycol <- tibble(treatment_sd = sd_treatment$sd_treatment,
                   residuals_sd = sd_residuals)

broom::tidyMCMC(sd_bycol, conf.int = TRUE, conf.method = "HPDinterval")
```

Last, we can also look at this so that we can get % of variance by transforming `sd_bycol` to percentages.

```{r percent_banova}
sd_percent_bycol <- sd_bycol/rowSums(sd_bycol) * 100

broom::tidyMCMC(sd_percent_bycol, estimate.method = "median",
         conf.int = TRUE, conf.method = "HPDinterval")
```
### 3.3 BANOVA post-hocs

We can use `emmeans` for contrasts, too. Here's a tukey test.

```{r tukey}
contrast(knees_b_em, method = "tukey")
```


We can visualize this using `tidybayes::gather_emmeans_draws`` to see the results of the contrast.

```{r vis_bayes_cont}
contrast(knees_b_em, method = "tukey") %>%
  gather_emmeans_draws() %>%
  ggplot(aes(x = .value, y = contrast)) +
  geom_halfeyeh() +
  geom_vline(xintercept = 0, color = "red", lty = 2)
```


Or maybe something that matches earlier visualizations
```{r vis_bayes_2}
contrast(knees_b_em, method = "tukey") %>%
  gather_emmeans_draws() %>%
  ggplot(aes(y = .value, x = contrast)) +
  geom_jitter(alpha = 0.05)+
  geom_hline(yintercept = 0, color = "red", lty = 2)
```


As you can see, `gather_emmeans_draws` lets us to a lot with categorical variables in a BANOVA context very easily. We can even use it to generate some interesting and useful visualizations of the means themselves with some additional geoms.

```{r vis_bayes_3}
gather_emmeans_draws(knees_b_em) %>%
  ggplot(aes(x = treatment, y = .value)) +
  stat_lineribbon(alpha = 0.25, fill = "gray25") +
  stat_pointinterval() 

gather_emmeans_draws(knees_b_em) %>%
  ggplot(aes(x = treatment, y = .value)) +
  geom_line(aes(group = .draw), alpha = 0.01) +
  stat_pointinterval(color = "darkred") 
  
```

We can even add this back to the original data.
```{r vis_bayes_4}

ggplot(knees,
       aes(x = treatment, y = shift)) +
  geom_point() +
  stat_pointinterval(data = gather_emmeans_draws(knees_b_em), 
                     mapping = aes(y = .value), color = "red", alpha = 0.4)

```
  
  
## 4. Final Exercise

Take two of the examples from the faded examples section. Execute one analysis using likelihood. Execute the other using Bayesian methods. Be sure to do all of the usual checks!