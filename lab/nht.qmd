---
title: "Null Hypothesis Testing with LMs and GLMS"
author: "Biol 607"
format: 
  html:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(htmltools.dir.version = FALSE)

```

## 1. P-Values and OLS with Mixed Categorical and Continuous Variable Models

To highlight all of the possibilities of p-values, let's look at our old data set looking at worker caste of naked mole rats and energy expenditure.

```{r}
library(readr)
library(ggplot2)
molerats <- read_csv("./data/18e4MoleRatLayabouts.csv")

ggplot(molerats,
       aes(x = lnmass, y = lnenergy, color = caste)) +
  geom_point() +
  stat_smooth(method = "lm")

```

Let's fit a model and check assumptions as usual...

```{r}
library(performance)
mole_mod <- lm(lnenergy ~ caste + lnmass, data= molerats)

check_model(mole_mod)
```

You are welcome to check the additivity assumption, but, I'll tell you - it's additive.

### 1.1 Coefficient Testing

So, first, we might want to look at raw coefficients. What is the slope of the relationship between mass and energy expenditure? What is the effect of caste (worker relative to lazy)?

We can see this with t-tests in the summary table

```{r}
summary(mole_mod)
```

Or we can make it neater with broom.

```{r}
library(broom)
tidy(mole_mod)
```

In either case, we'd reject the null hypothesis that there was no mass-energy relationship, and likely see that worker's are different from lazy mole rats.

### 1.2 F-Tests

To be clearer, do these predictors explain variation in our model? For this, we want F tests, with the null hypothesis that the predictors do not matter.

Now, R has a builtin `anova()` function - but, it uses Type I sums of squares. These are sequential.  So, consider the following for caste.

```{r}
anova(mole_mod)

no_caste <- lm(lnenergy ~ lnmass, data = molerats)

anova(mole_mod, no_caste)
```

Uhhhh.... which is it? What's happening? Here, `anova()` is going sequentially. So, the actual comparison we see for caste isn't a model with caste and mass v. one with just mass, but instead....

```{r}
int_only <- lm(lnenergy ~ 1, data = molerats)
caste_only <- lm(lnenergy ~ caste, data = molerats)

anova(int_only, caste_only)
```

Ew. Except, the p and F values are also off, because they don't have the right denominator DF due to the lack of mass being in the model, and there are likely backdoor effects, and.... it's just problematic.

We want marginal, or type II sums of squares. These are in the `car` package with `car::Anova()` (note the capital A)

```{r}
library(car)
Anova(mole_mod)
```

Lovely. We now have done the correct model comparison.

Note, if we had interactions, the F tests and p-values for the additive components would stay the same. There is something called a Type III SS which would enter each term as if it was the last one - but that leads to some nonsensical models. I'll leave it to you to fit a model with an interaction and try `Anova()` with `type = "III"` versus the default `type = "II"`

### 1.3 Post-Hoc Tests

This is great, but what about then doing post-hoc comparisons of caste controlling for mass? Well, we have emmeans! And now, the corrections affect the p-values. We only have two groups here, so..... we can't see it, but, instead of having to go to `confint()` we can just just use `contrast()` which will perform t-tests


```{r}
library(emmeans)

mole_em <- emmeans(mole_mod, ~caste)

contrast(mole_em, "pairwise")

contrast(mole_em, "pairwise", adjust = "none")

```
### 1.4 Example

Great! Try this out with the Zooplankton predation experiment. Look at the F-tests. Then evaluate posthoc tests only for those F-tests where we would reject the null.

```{r}
zooplankton <- read.csv("./data/18e2ZooplanktonDepredation.csv")
```

If you really want to have fun, try it with the algal herbivory experiment with an interaction between tide height and herbivory.

```{r}
intertidal <- read.csv("./data/18e3IntertidalAlgae.csv")
```

## 2. P-Values and Likelihood

For this, let's look at the binomial logistic regression between cryptosporidium dose and infection in mice.

```{r}
library(dplyr)

mouse <- read_csv("./data/cryptoDATA.csv") |>
  mutate(Porportion = Y/N)

mouse_plot <- ggplot(mouse,
       aes(x = Dose, y = Porportion)) +
  geom_point()

mouse_plot

mouse_glm <- glm(Porportion ~ Dose,
                 weights = N,
                 data = mouse,
                 family = binomial)
```

### 2.1 Likelihood Profiles and Wald Tests

First, how do we look at a likelihood profile to make sure our model is well behaved? There are a number of libraries, but the builtin MASS has a profile function that can then be used to evaluate things visually looking at the square root of the log-likelihood profile.

```{r}
library(MASS)

mouse_prof <- profile(mouse_glm)

plot(mouse_prof)

```

Looks good.

If we look at the model, we get Wald Z-Tests which are an approximation of the profile.

```{r}
summary(mouse_glm)
```

How good? Well, we can compare the confidence interval from the approximation to that of the actual profile.

```{r}
confint(mouse_glm)

confint(mouse_prof)
```

Not 100% the same, but so close that there's little to be gained from not using the approximation.

Note, emmeans also uses Wald Z-Tests if you are comparing categorical values.

### 2.2 Likelihood Ratio Chi-Square Tests

Here again, we're comparing models. And we want to do it in with marginal model comparisons - not sequential. So, we can again use `car::Anova()`

```{r}
Anova(mouse_glm)
```

Note - not every object type defaults to `anova` being type I, so read the documentation for any new package or object type you use.

### 2.3 Example

Grab the Keeley data, and as Richness is either Poisson of negative binomial (try either!), fit a model with firesev, cover, elev, and their interactions. Evaluate for which predictors we can reject the null hypothesis that adding the predictor does not improve the deviance. For your interest, compare type I, II, and III outcomes.

```{r}
keeley <- read_csv("./data/Keeley_rawdata_select4.csv")
```