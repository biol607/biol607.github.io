<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Cross Validation and Model Selection</title>
    <meta charset="utf-8" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/shinobi.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
    <script src="libs/anchor-sections/anchor-sections.js"></script>
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Cross-Validation and AIC&lt;br&gt;

&lt;!-- next year, more on overfitting and generality
versus specificity --&gt;

![:scale 55%](images/cv/princess_bride_cv.jpg)


---

# HOT ROACHES!
&lt;br&gt;&lt;br&gt;
.pull-left[
- Do American Cockroaches sense surrounding temperatures and respond?

- Survey of activity by the prothoracic ganglion in different temperature regimes

- Murphy and Heath 1983 J. Exp. Biol

]


.pull-right[
![](./images/cv/roach_nipcam_com.jpg)
]

---

# Which is best?



&lt;img src="crossvalidation_files/figure-html/roachplot_int-1.png" style="display: block; margin: auto;" /&gt;
  
---

# Which is best?

&lt;img src="crossvalidation_files/figure-html/roach_poly_plot-1.png" style="display: block; margin: auto;" /&gt;

---

# Applying Different Styles of Inference

- **Null Hypothesis Testing**: What's the probability that things are not influencing our data?
      - Deductive

- **Cross-Validation**: How good are you at predicting new data?
      - Deductive
      
- **Model Comparison**: Comparison of alternate hypotheses
      - Deductive or Inductive

- **Probabilistic Inference**: What's our degree of belief in a data?
      - Inductive
      
---


# Applying Different Styles of Inference

.grey[
- **Null Hypothesis Testing**: What's the probability that things are not influencing our data?
      - Deductive
]

- **Cross-Validation**: How good are you at predicting new data?
      - Deductive
      
- **Model Comparison**: Comparison of alternate hypotheses
      - Deductive or Inductive


.grey[
- **Probabilistic Inference**: What's our degree of belief in a data?
      - Inductive
]

---

# Validating Across Models

1. Out of Sample Prediction

2. Train-Test Random Cross Validation

3. K-Fold Cross Validation

4. LOOCV

5. AIC and Model Comparison

---

# What is Out of Sample Prediction

1. We fit a model  

2. We have a new sample(s) with a full set of predictors

3. We apply the model to our new prediction

4. We see how badly we deviate from our fit model

---

# Common Out of Sample Metrics

`\(MSE = \frac{1}{n}\sum{(Y_i - \hat{Y})^2}\)`
     - In units of sums of squares

`\(RMSE = \sqrt{\frac{1}{n}\sum{(Y_i - \hat{Y})^2}}\)`
     - In units of response variable!
     - Estimate of SD of out of sample predictions
     
`\(Deviance = -2 \sum log(\space p(Y_i | \hat{Y}, \theta)\space)\)`
     - Probability-based
     - Encompasses a wide number of probability distributions
     - Just MSE for gaussian linear models!
     
---
# Evaluating and Out of Sample Point: What if we had left out the 1st row of Roach data?

&lt;img src="crossvalidation_files/figure-html/one_loo_roach-1.png" style="display: block; margin: auto;" /&gt;

---
# We Can See This Model is Worse at Prediction

&lt;img src="crossvalidation_files/figure-html/one_loo_roach_int-1.png" style="display: block; margin: auto;" /&gt;


---
# Evaluating Predictive Ability of Statistical Models: Cross-Validation

1. Fit a model on a **training** data set

2. Evaluate a Model on a **TEST** data set

3. Compare predictive ability of competing models with MSE, Deviance, etc.

---

# But.... what data do I use for training and testing?
## Random Cross-Validation

- Cross-validating on only one point could be biased by choice of poing

- So, choose a random subset of your data!

- Typically use a 60:40 split, or 70:30 for lower sample size

- Calculate fit metrics for alternate models

---
# A Random Cross-Validation Sample

&lt;img src="crossvalidation_files/figure-html/unnamed-chunk-1-1.png" style="display: block; margin: auto;" /&gt;

---
# The Fits

&lt;img src="crossvalidation_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

---
# Cross-Validation: the Fits

&lt;img src="crossvalidation_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---

# Results of Random CV

RMSE Temperature Model:

```
[1] 27.31889
```

RMSE Intercept Only Model:

```
[1] 32.00178
```

This is the estimate of the SD of the training set - which is acceptable for your predictions?

---

# Validating Across Models

1. Out of Sample Prediction

2. Train-Test Random Cross Validation

3. .red[K-Fold Cross Validation]

4. LOOCV

5. AIC and Model Comparison

---
class: center, middle

# But, wait, what if I choose a bad section of the data by chance?

---

# K-Fold Cross Validation

- Data is split into K sets of training and testing folds

- Performance is averaged over all sets

.center[
![](./images/cv/kfold_performance.png)
]

---
# Our Models

&lt;img src="crossvalidation_files/figure-html/roachplot_int-1.png" style="display: block; margin: auto;" /&gt;

---

# Five-Fold CV


|id    |      mse|     rmse|
|:-----|--------:|--------:|
|Fold1 | 566.6716| 23.80487|
|Fold2 | 482.6707| 21.96977|
|Fold3 | 493.9591| 22.22519|
|Fold4 | 586.6068| 24.21997|
|Fold5 | 515.8802| 22.71300|

Temperature Model Score: 529.1576829  

Intercept Only Score: 788.2974 &lt;!-- eh, I was lazy, and just reran the above with a different model --&gt;

---

# But what if there is some feature in your data that splits it into groups? 
## Stratified K-Fold CV!
.center[.middle[
![](images/cv/stratified_kfold.png)
]]

---

# Validating Across Models

1. Out of Sample Prediction

2. Train-Test Random Cross Validation

3. K-Fold Cross Validation

4. .red[LOOCV]

5. AIC and Model Comparison

---
# Problem: How Many Folds?

- What is a good number?
     - More folds = smaller test dataset
     - Bias-Variance tradeoff if also looking at coefficients

--

- 5 and 10 are fairly standard, depending on data set size

--


- More folds = closer to average out of sample error

--


- But, more folds can be computationally intensive

--

- Still, Leave One Out Cross Validation is very powerful

---
# LOOCV (Leave One Out Cross-Validation)

.center[.middle[
![](./images/cv/LOOCV.gif)

]]

---
# LOOCV (Leave One Out Cross-Validation)
.center[.middle[
![](./images/cv/loocv.png)

]]

---
# LOOCV Comparison of Out of Sample Deviance (MSE)

Rate Model:569.58


Intercept Only Model: 818.68

&lt;img src="crossvalidation_files/figure-html/roachplot_int-1.png" style="display: block; margin: auto;" /&gt;

---
#What abour our polynomial models?

&lt;img src="crossvalidation_files/figure-html/roach_poly_plot-1.png" style="display: block; margin: auto;" /&gt;

---

# Using LOOCV to Compare Polynomial Fits

&lt;img src="crossvalidation_files/figure-html/loocv_poly-1.png" style="display: block; margin: auto;" /&gt;

---

# Validating Across Models

1. Out of Sample Prediction

2. Train-Test Random Cross Validation

3. K-Fold Cross Validation

4. LOOCV

5. .red[AIC and Model Comparison]


---
class: center, middle

# This is all well and very computationally intensive, but, what about when we have n = 1e5, or many different models?

---

# Can our Training Deviance Provide an Approximation of our Test Deviance?



&lt;img src="crossvalidation_files/figure-html/traintest_plot-1.png" style="display: block; margin: auto;" /&gt;

---

# Does the Gap Increase with Number of Parameters?

&lt;img src="crossvalidation_files/figure-html/k_plot-1.png" style="display: block; margin: auto;" /&gt;

.large[.center[Slope = 1.89 â‰ˆ 2]]

---
# Enter the AIC
.pull-left[
![](./images/mmi/hirotugu_akaike.jpg)
]

.pull-right[
- `\(E[D_{test}] = D_{train} + 2K\)`  
  
- This is Akaike's Information Criteria (AIC)  

]

`$$\Large AIC = Deviance + 2K$$`

---
# AIC and Prediction

- AIC optimized for forecasting (out of sample deviance)  

- Approximates average out of sample deviance from test data

- Assumes large N relative to K  
    - AICc for a correction  

---
# But Sample Size Can Influence Fit...
&lt;br&gt;&lt;br&gt;
`$$\large AIC = -2log(L(\theta | x)) + 2K$$`

&lt;br&gt;&lt;br&gt;&lt;br&gt;
`$$\large AICc = AIC + \frac{2K(K+1)}{n-K-1}K$$`


---
# How can we Use AIC Values?

`$$\Delta AIC = AIC_{i} - min(AIC)$$`


Rules of Thumb from Burnham and Anderson(2002):


--

- `\(\Delta\)` AIC `\(&lt;\)` 2 implies that two models are similar in their fit to the data  

--

- `\(\Delta\)` AIC between 3 and 7 indicate moderate, but less, support for retaining a model

--

- `\(\Delta\)` AIC `\(&gt;\)` 10 indicates that the model is very unlikely 

---
# A Quantitative Measure of Relative Support

`$$w_{i} = \frac{e^{-\Delta_{i}/2 }}{\displaystyle \sum^R_{r=1} e^{-\Delta_{i}/2 }}$$`

Where `\(w_{i}\)` is the *relative support* for model i
compared to other models in the set being considered.

Model weights summed together = 1

---
# Let's Apply AIC to our Polynomials

&lt;img src="crossvalidation_files/figure-html/roach_poly_plot-1.png" style="display: block; margin: auto;" /&gt;

---
# Model Information for Polynomial Fits

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;   &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Modnames &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; K &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; AIC &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Delta_AIC &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; ModelLik &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; AICWt &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; LL &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Cum.Wt &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 522.36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -256.18 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.44 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 523.38 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.60 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.26 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.69 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.70 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 5 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.34 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 2.98 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.23 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.79 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 1 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 1 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 525.92 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.55 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.17 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.07 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -259.96 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.87 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 6 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 6 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 526.67 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.31 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.33 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.92 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 2 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 526.89 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.53 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -259.44 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.96 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 7 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 7 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 528.27 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.91 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.99 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 8 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 530.27 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.91 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.01 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.14 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 9 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 9 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 532.24 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 9.87 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.01 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -255.12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; 10 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Order 10 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 12 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 533.75 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 11.39 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -254.88 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.00 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

.center[So... how much better are the top models? What about Parsimody? What would you say?]

---
# Inferential Frameworks of Today

- **Cross-Validation**: How good are you at predicting new data?
      - Deductive
      - Chose model with best predictive ability!
      
- **Model Comparison**: Comparison of alternate hypotheses
      - Deductive or Inductive
      - Either compare models to elminiate poor fits
      - Or... compare multiple models to determine how a system works
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="my_macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
