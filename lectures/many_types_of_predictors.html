<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Many Types of Categories: Multi-way and Factorial ANOVA</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/shinobi.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">


class: center, middle

# Many Types of Predictors
![](./images/many_predictors/stop-using-linear-regression.jpg)



---
class: center, middle

# Etherpad

&lt;br&gt;&lt;br&gt;

https://etherpad.wikimedia.org/p/607-many-predictors-2022

---

# We've Now Done Multiple Continuous Predictors


`$$\large y_{i} = \beta_{0} + \sum \beta_{j}x_{ij} + \epsilon_{i}$$`

`$$\large \epsilon_{i} \sim \mathcal{N}(0, \sigma)$$`
---
# We've Previously Done One Categorical Variable with Many Levels 

`$$\large y_{ij} = \beta_{0} + \sum \beta_{j}x_{ij} + \epsilon_{ij}$$`
  
`$$\large \epsilon_{ij} \sim \mathcal{N}(0, \sigma), \qquad x_{i} = 0,1$$`  

--
&lt;br&gt;&lt;br&gt;

(hey, wait, isn't that kinda the same model.... but where you can only belong to one level of one category?)

---
# Now... Two Categories, Each with Many Levels, as Predictors

`$$\large y_{ijk} = \beta_{0} + \sum \beta_{i}x_{ik} + \sum \beta_{j}x_{jk} + \epsilon_{ijk}$$`  
  
`$$\large \epsilon_{ijk} \sim N(0, \sigma^{2} ), \qquad x_{\_k} = 0,1$$` 

--

- This model is similar to MLR, but, now we multiple categories instead of multiple continuous predictors  
 
--

- This can be extended to as many categories as we want with linear algebra  
  
`$$Y = \beta X + \epsilon$$`
---
class: center, middle

![:scale 50%](./images/many_predictors/reliable_linear_model_spongebob.png)

---
# Multiple Predictors: A Graphical View

.center[ ![:scale 60%](./images/23/regression2.png) ]


- Curved double-headed arrow indicates COVARIANCE between predictors that we account for.  

- We estimate the effect of each predictor **controlling** for all others.  
  
- Can be continous or categorical predictors

---
# We Commonly Encounter Multiple Predictors in Randomized Controlled Blocked Designs
.center[ ![:scale 70%](./images/21/blocked_designs/Slide4.jpg) ]

---
# An Experiment with Orthogonal Treatments: A Graphical View

.center[![:scale 60%](./images/23/anova.png)]

- This is convenient for estimation  

- Observational data is not always so nice, which is OK!  

---
# Effects of Stickleback Density on Zooplankton
&lt;br&gt;&lt;br&gt;
.pull-left[![](./images/21/daphnia.jpeg)]
.pull-right[![](./images/21/threespine_stickleback.jpeg)]  
   
   
.bottom[Units placed across a lake so that 1 set of each treatment was ’blocked’ together]

---
# Treatment and Block Effects

&lt;img src="many_types_of_predictors_files/figure-html/zooplankton_boxplot-1.png" style="display: block; margin: auto;" /&gt;

---
# Multiway Categorical Model
- Many different treatment types  
     - 2-Way is for Treatment and block
     - 3-Way for, e.g., Sticklebacks, Nutrients, and block
     - 4-way, etc., all possible  

--

- For experiments, we assume treatments are fully orthogonal  
      - Each type of treatment type A has all levels of treatment type B
      - E.g., Each stickleback treatment is present in each block  

--

- Experiment is **balanced** for **simple effects**  
      - Simple effect is the unique combination of two or more treatments  
      - Balance implies the sample size for each treatment combination is the same 
      - But, hey, this is more for inference, rather than **estimation**

---
# Fitting a Model with Mutiple Categorical Predictors

```r
zoop_lm &lt;- lm(zooplankton ~ treatment + 
                block, data=zoop)

zoop_lm
```

```

Call:
lm(formula = zooplankton ~ treatment + block, data = zoop)

Coefficients:
  (Intercept)  treatmenthigh   treatmentlow         block2         block3  
    3.420e+00     -1.640e+00     -1.020e+00      1.039e-15     -7.000e-01  
       block4         block5  
   -1.000e+00     -3.000e-01  
```

--
 Note the treatment contrasts!

---
# Assumptions of Categorical Models with Many Categories
-   Independence of data points  

-   No relationship between fitted and residual values  
     -   .red[Additivity (linearity) of Treatments]
  
-   Normality within groups (of residuals)  
  
-   Homoscedasticity (homogeneity of variance) of groups  
  
- No *collinearity* between treatments
  

---
# The Usual on Predictions
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;

---
# Linearity (and additivity!)
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;

---
# What is Non-Additivity?
The effect of category depends on another - e.g. this grazing experiment

&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;

---
# Non-Additivity is Parabolic

&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;

---
![](images/many_predictors/bad_model.jpg)

---
# Normality!
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---
# HOV!
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---
# Collinearity!
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

- by definition, not a problem in an experiment

---
# How do We Understand the Modeled Results?

- Coefficients (but treatment contrasts)  
  
  
- Expected means of levels of each category
     - Average over other categories
  
  
- Differences between levels of each category

---
# Coefficients and Treatment Contrasts

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 3.42 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.31 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; treatmenthigh &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.64 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.29 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; treatmentlow &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.02 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.29 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; block2 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; block3 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.70 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; block4 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -1.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; block5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.30 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.37 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Intercept is block 1, treatment control  
  
- Other coefs are all deviation from control in block 1  

---
# Means Averaging Over Other Category


```
 treatment emmean    SE df lower.CL upper.CL
 control     3.02 0.205  8    2.548     3.49
 high        1.38 0.205  8    0.908     1.85
 low         2.00 0.205  8    1.528     2.47

Results are averaged over the levels of: block 
Confidence level used: 0.95 
```

```
 block emmean    SE df lower.CL upper.CL
 1       2.53 0.264  8    1.924     3.14
 2       2.53 0.264  8    1.924     3.14
 3       1.83 0.264  8    1.224     2.44
 4       1.53 0.264  8    0.924     2.14
 5       2.23 0.264  8    1.624     2.84

Results are averaged over the levels of: treatment 
Confidence level used: 0.95 
```

---
# Visualize the Expected Means

&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---
# Differences Between Treatments


```
 contrast       estimate    SE df lower.CL upper.CL
 control - high     1.64 0.289  8    0.972   2.3075
 control - low      1.02 0.289  8    0.352   1.6875
 high - low        -0.62 0.289  8   -1.288   0.0475

Results are averaged over the levels of: block 
Confidence level used: 0.95 
```


---
# Many Additive Predictors

1.   Multiple Linear Regression

2.   Many Categories with Many Levels  

3.   &lt;font color = "red"&gt;Combining Categorical and Continuous Predictors&lt;/font&gt;

---
# It's All One

**The Linear Model**
`$$\boldsymbol{Y} = \boldsymbol{b X} + \boldsymbol{\epsilon}$$`

--

**Multiple Continuous Predictors**
`$$y_{i} = \beta_{0} + \sum \beta_{j}x_{ij} + \epsilon_{i}$$`

--

**Many Categorical Predictors**
`$$y_{ijk} = \beta_{0} + \sum \beta_{i}x_{ik} + \sum \beta_{j}x_{jk} + \epsilon_{ijk}$$`  


---
# Mixing Continuous and Categorical Predictors: Analysis of Covariance

`$$y_{ij} = \beta_0   + \sum\beta_j x_{ij} + \beta_{j+1}x_{i} + \epsilon_{ij}$$`  

$$ x_{ij} = 0,1 \qquad \epsilon \sim \mathcal{N}(0,\sigma)$$


-   Categorical Variable + a continuous predictor  
  
-   Often used to correct for a gradient or some continuous variable affecting outcome  
  
-   OR used to correct a regression due to additional groups that may throw off slope estimates  
      - e.g. Simpson's Paradox: A positive relationship between test scores and academic performance can be masked by gender differences

---
# Simpson's Paradox
![](./images/many_predictors/simpsons_paradox.jpg)


---
# What is Simpson's Paradox: Penguin Example

&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;


---
# What is Simpson's Paradox: Penguin Example

&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-13-1.png" style="display: block; margin: auto;" /&gt;

--

Note: This can happen with just continuous variables as well

---

# Neanderthals and Categorical/Continuous Variables

![:scale 60%](./images/23/neanlooking.jpeg)  

Who had a bigger brain: Neanderthals or us?

---
# The Means Look the Same...

&lt;img src="many_types_of_predictors_files/figure-html/neand_boxplot-1.png" style="display: block; margin: auto;" /&gt;


---
# But there appears to be a Relationship Between Body and Brain Mass

&lt;img src="many_types_of_predictors_files/figure-html/neand_plot-1.png" style="display: block; margin: auto;" /&gt;


---
# And Mean Body Mass is Different

&lt;img src="many_types_of_predictors_files/figure-html/neand_boxplot2-1.png" style="display: block; margin: auto;" /&gt;

---
class: center, middle 
![](images/23/redo_analysis.jpg)

---
# Categorical Model with a Continuous Covariate for Control




&lt;img src="many_types_of_predictors_files/figure-html/neand_plot_fit-1.png" style="display: block; margin: auto;" /&gt;

Evaluate a categorical effect(s), controlling for a *covariate* (parallel lines)  
   
Groups modify the *intercept*.


---
# Assumptions are the Same!
  
-   Independence of data points
  
-   Additivity of Treatment and Covariate (Parallel Slopes)  
  
-   Normality and homoscedacticity within groups (of residuals)  
  
-   No relationship between fitted and residual values  
  

---
# Linearity Assumption KEY
&lt;img src="many_types_of_predictors_files/figure-html/zoop_assumptions-1.png" style="display: block; margin: auto;" /&gt;

---
# Test for Parallel Slopes
We fit a model where slopes are not parallel:

`$$y_{ijk} = \beta_0 + \beta_{1}x_1  + \sum_{j}^{i=1}\beta_j x_{ij} + \sum_{j}^{i=1}\beta_{k}x_1 x_{ij} + \epsilon_ijk$$`

--

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 4.2534953 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.9768911 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; speciesrecent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.1809274 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 1.0623095 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; lnmass &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.7135471 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2270081 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; speciesrecent:lnmass &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.2594885 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.2481073 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

If you have an interaction, welp, that's a different model - slopes vary by group!

---
# VIF Also *Very* Important
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;

---
# Usual Normality Assumption
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-15-1.png" style="display: block; margin: auto;" /&gt;

---
# Usual HOV Assumption
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;

---
# Usual Outlier Assumption
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;

---
# The Results

- We can look at coefficients  
  
- We can look at means adjusted for covariate   
  
- Visualize! Visualize! Visualize!  

---
# Those Coefs

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; term &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; std.error &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 5.19 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.40 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; speciesrecent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.07 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.03 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; lnmass &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.50 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.09 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

- Intercept is species = neanderthal, but lnmass = 0?  
  
- Categorical coefficient is change in intercept for recent  
  
- lnmass coefficient is change in ln brain mass per change in 1 unit of ln mass  

---
# Groups Means at Mean of Covariate
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; species &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; emmean &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SE &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; df &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; lower.CL &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; upper.CL &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; neanderthal &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.272 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.024 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.223 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.321 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; recent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.342 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.013 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.317 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 7.367 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

Can also evaluate for other levels of the covariate as is interesting

---
# We Can Compare Groups Adjusting for Covariates
.center[ ![](./images/many_predictors/bonferroni_meme.jpg) ]

---
# Difference Between Groups at Mean of Covariate
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; contrast &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; estimate &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; SE &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; df &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; lower.CL &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; upper.CL &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; neanderthal - recent &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.07 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 0.028 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.128 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -0.013 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# Visualizing Result Says it All!
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;

---
# Or Plot at the Mean Level of the Covariate
&lt;img src="many_types_of_predictors_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;

---
# Extensions of the Linear Additive Model

- Wow, we sure can fit a lot in there!  

- Categorical is just continuous as 0/1   
  
- So, we can build a LOT of models, limited only by our imagination!  
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="my_macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
