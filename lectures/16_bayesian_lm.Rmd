---
title:
output:
  revealjs::revealjs_presentation:
    reveal_options:
      slideNumber: true
      previewLinks: true
    theme: white
    center: false
    transition: fade
    self_contained: false
    lib_dir: libs
    css: style.css
---

## Fitting Linear Models with Bayes
![image](./images/15/bayes.png)

```{r prep, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE}
library(knitr)
opts_chunk$set(fig.height=4.5, comment=NA, 
               warning=FALSE, message=FALSE, 
               dev="jpeg", echo=FALSE)
library(dplyr)
library(tidyr)
library(broom)
library(ggplot2)
library(rstanarm)

#legacy - fix
library(MCMCglmm)
library(coda)

options(mc.cores = parallel::detectCores())

```

## Bayesian Inference

![image](./images/15/neon_bayes_theorem.jpeg){width="40%"}\

<font size="6">

-   Estimate probability of a parameter

-   State degree of believe in specific parameter values

-   Evaluate probability of hypothesis given the data

-   Incorporate prior knowledge

</font>


## Today

-   Markov Chain Monte-Carlo Sampling

-   Fitting and evaluating linear models fit with MCMC

-   Modifying our Prior


## Bayes Theorem Expanded
<div style="text-align:left; font-size:24pt">
$p(\theta | X) = \frac{p(X | \theta)P(\theta)}{\displaystyle \sum_{i=0}^{j} p(X | \theta_{i})p(\theta_{i})}$

- Algebraically Solvable \
\

$p(\theta | X) = \frac{p(X | \theta)P(\theta)}{\int p(X | \theta)p(\theta)d\theta}$

- Analytically Solveable for Conjugate Priors \
\
$p(\theta | X) = \frac{\int p(X | \theta)P(\theta|\eta)p(\eta)d\eta}{\int\int p(X | \theta)p(\theta)d\theta d\eta}$

- Hierarchical Model: need numerical integration approach with random
hyperparameters</div>

## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic, echo=FALSE, cache=TRUE} 
set.seed(100)
mod <- stan_glm(x ~ 1, data=data.frame(x=rnorm(50)), verbose=FALSE, family=gaussian())
plot(mod, plotfun="stan_trace")
```



## Markov Chain Monte Carlo Sampling (MCMC)

<p align="left">If we cannot analytically solve a distribution, we can still simulate
from it:</p>

-   Chose a set of starting values X at t=0

-   Chose a random set of parameters, Y, based on X

-   Calculate an acceptance ratio, $\alpha$, based on P(Y)/P(X)

-   If $\alpha \ge 1$ X(t+1) = Y

-   Otherwise, select a uniorm random number between 0 and 1, U

-   If $U \le \alpha$, X(t+1) = Y. Otherwise, X(t+1) = X.

-   Rinse and repeat

(Note, this is the Metropolis-Hastings Algorithm - there are others)


## Markov Chain Monte Carlo Sampling (MCMC)

<p align="left">This is a time series. To use it for inference to sample from the final
stationary distribution:</p>

-   Discard a ’burn in’ set of samples

-   'Thin' your chain or use other methods to reduce temporal autocorrelation

-   Examine chain for convergence on your posterior distribution

-   Evaluate multiple chains to ensure convergence to a single
    distribution


## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic1, echo=FALSE} 

set.seed(100)
mod <- MCMCglmm(x ~ 1, data=data.frame(x=rnorm(50)), verbose=FALSE)
modNoThin <- MCMCglmm(x ~ 1, data=data.frame(x=rnorm(50)), verbose=FALSE, thin=1, burnin=0)

plot(modNoThin$Sol[1], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic2, echo=FALSE} 
plot(modNoThin$Sol[1:2], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic3, echo=FALSE} 
plot(modNoThin$Sol[1:3], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic4, echo=FALSE} 
plot(modNoThin$Sol[1:4], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic5, echo=FALSE} 
plot(modNoThin$Sol[1:5], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic6, echo=FALSE} 
plot(modNoThin$Sol[1:6], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphic100, echo=FALSE} 
plot(modNoThin$Sol[1:100], type="b", ylab="Value", xlab="Iteration")

```



## Markov Chain Monte Carlo Sampling (MCMC)

```{r mcmcgraphicThinned, echo=FALSE} 
plot(seq(1,100,10),modNoThin$Sol[seq(1,100,10)], type="b", ylab="Value", xlab="Iteration", main="Thinned")
```

## Multiple Chains to Check Convergence and Improve Answer
```{r mcmcgraphic, echo=FALSE, cache=TRUE} 
```

##
<br><br><br>
<h1>Linear Modeling with Bayes

## Software Options for MCMC

-   WinBUGS <http://www.mrc-bsu.cam.ac.uk/bugs/>

-   OpenBUGS <http://www.openbugs.info/w/>

-   JAGS <http://mcmc-jags.sourceforge.net/>

-   STAN <http://mc-stan.org/>
    - **rstanarm**
    - rethinking

-   MCMCglmm in R

-   MCMCpack in R

## rstanarm

-   Powerful package that fits bayesian models using 
    MCMC with Hamiltonian Updating (reduced autocorrelation in chain)

-   Available tools to tweak priors

-   Flexible in error distribution

-   Can accomodate random effects, autocorrelation, etc

-   Uses STAN to fit models, but same syntax as base R models

-   For more flexible correlation structure, `MCMCglmm`

-   For maximum flexibility, *rethinking* or *rstan*


## Bayesian Pufferfish
```{r pufferload}
puffer <- read.csv("./data/11/16q11PufferfishMimicry Caley & Schluter 2003.csv")
```
<div id = "left">
- Pufferfish are toxic/harmful to predators  
<br>
- Batesian mimics gain protection from predation
<br><br>
- Evolved response to appearance?
<br><br>
- Researchers tested with mimics varying in toxic pufferfish resemblance
</div>

<div id = "right">
![image](./images/11/puffer_mimics.jpg){width="80.00000%"}\
</div>

## Does Resembling a Pufferfish Reduce Predator Visits?
```{r puffershow}
pufferplot <- ggplot(puffer, mapping=aes(x=resemblance, y=predators)) +
  geom_point(size=2) +
  ylab("Predator Approaches per Trial") + 
  xlab("Dissimilarity to Toxic Pufferfish") +
  theme_bw(base_size=17)

pufferplot
```

## The Steps of Statistical Modeling
1. What is your question?
2. What model of the world matches your question?
3. Build a model
4. Evaluate model assumptions
5. Evaluate model results
6. Visualize

## Implementing the Puffer Model in rstanarm

```{r pufferstan, echo=TRUE, cache=TRUE}
set.seed(100)
puffer_mod <- stan_glm(predators ~ resemblance, 
                      data=puffer,
                      family=gaussian())

```

## What were the priors?

```{r pufferstan_showprior, echo=TRUE, eval=FALSE}
puffer_mod_p <- stan_glm(predators ~ resemblance, 
                      data=puffer,
                      family=gaussian(),
                      prior=normal(0, 2.5),
                      prior_intercept=normal(0,10))
```

Note that these are weakly informative!

##
<br><br><br>
<h1 style="text-align:left">All assumptions of linear regression hold - and then there are a few checks for MCMC fits</h1>

## Good ole' QQ

```{r qq_stan}
qqnorm(residuals(puffer_mod))
qqline(residuals(puffer_mod))
```



## But - often use simulated posterior estimates
```{r resid_hist}
pp_check(puffer_mod, check = "resid", bins=10) +
  ggtitle("Residual Histogram for three simulated datasets")
```

## Observed v. Average of Simulated Fitted Value

```{r obs_v_fit}
pp_check(puffer_mod, check = "scatter", nreps=3)
```

## Do Simulated Posterios of the Data Fit our Observations?
Blue = Distribution of our observations, Lines = Simulations
```{r pp_check}
pp_check(puffer_mod)
```


## Does Distribution of Sample Estimates Match Distribution of Simulated Sample Estimates?
```{r pp_hist}
pp_check(puffer_mod, check = "test", test = c("mean"))
```

## Does Distribution of Sample Estimates Match Distribution of Simulated Sample Estimates?
```{r pp_hist_2}
pp_check(puffer_mod, check = "test", test = c("mean", "sd"))
```


## How sensitive is our simulation to leaving out one value?
```{r loo}
plot(rstanarm::loo(puffer_mod), label_points = TRUE, cex=1.1)
```

Only one point with a moderate test statistic - not bad! If >1, inspect that point!

## 
<br><br>
<h1><p align="left">These are all data and error generating process checks. If they fail, you may need to respecify your model (or your prior)</p></h1>

## MCMC diagnostics - Did we converge?
```{r converge}
plot(puffer_mod, pars = c("(Intercept)", "resemblance", "sigma"), plotfun="stan_trace")
```

## Are our posterior distributions well behaved?
```{r check}
plot(puffer_mod, pars = c("(Intercept)", "resemblance", "sigma"), 
     ci_level = 0.67, outer_level = 1, show_density = TRUE) +
  ggtitle("Posterior Distributions with 67% Credible Intervals")
```

## 
<br><br><br>
<h1 style="text-align:left">These are all checks of the model fitting process. If they fail, either tweak the MCMC process (e.g., burnin, nsims), or your model is incompatible with the data</h1>

## Finally - the Parameters
```{r mcmc_params}
plot(puffer_mod, fill_color = "skyblue4", est_color = "maroon", 
     pars = c("(Intercept)", "resemblance", "sigma")) +
  ggtitle("Posterior Medians with 80% and 95% Credible Intervals")

```

## So.... what did we get?
```{r puffer_out}
summary(puffer_mod)
```

## Or, just look at your Credible Interval
\
\
<p align="left">For 80% Credible Interval:</p>  
\
```{r posterior}
posterior_interval(puffer_mod, prob=0.8)
```

## What is the weight of the tail less that 0?
```{r pred}
post_puffer <- as.data.frame(puffer_mod)
```
Weight of Intercept &le; 0? `r sum(post_puffer[,1]<0)/nrow(post_puffer)`  
\
Weight of Slope &le; 0? `r sum(post_puffer[,2]<0)/nrow(post_puffer)`

## Talking about Uncertainty the IPCC Way
![](images/15/ipcc_uncertainty_ar5.jpg)

## Compare to LM
Bayesian Fit
```{r compare_lm}
knitr::kable(tidy(puffer_mod,intervals = TRUE))
```

LM Fit
```{r compare_lm_2}
knitr::kable(tidy(lm(predators ~ resemblance, data=puffer)))
```

##

<h1 style="text-align:left">OK, ok, but what about the prior that we get all of the as for?</h1>

## See your posterior relative to your prior
```{r post_prior, cache=TRUE}
posterior_vs_prior(puffer_mod) +
  ggtitle("Default Priors")
```

## Adding a stronger prior
<br>
```{r prior, cache=TRUE, echo=TRUE}
set.seed(100)
puffer_mod_prior <- stan_glm(predators ~ resemblance, 
                      data=puffer,
                      family=gaussian(),
                      prior = normal(10,1),
                      prior_intercept = normal(2,1))
```

## How influential was that new prior?
```{r post_prior_strong, cache=TRUE}
posterior_vs_prior(puffer_mod_prior) +
  ggtitle("Strong Priors")
```

## Compare results!
<p align="left">Weak Prior:
```{r weak_prior}
posterior_interval(puffer_mod)
```

\
Strong Prior:</p>
```{r strong_prior}
posterior_interval(puffer_mod_prior)
```

## In Conclusion...

- Yes, it's more fidly and there are more assumptions  \
\
- BUT - you can now talk in the language or probability  
\
- Inherently recognizes "All models are wrong, some are useful"
